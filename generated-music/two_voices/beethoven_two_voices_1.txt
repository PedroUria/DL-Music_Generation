notes_encoded = load("beethoven", "sonata", 10, time_step=0.2)
# Code used to train the network. Note that even if you run this you will not get the same network
# net, l, ll = train_lstm_loss_whole_seq(100, n_epochs=100, lr=0.01)
# To save the model
# torch.save(net.state_dict(), 'beethoven_both_stacked_1.pkl')
net = LSTMMusic(178, 178).cuda()
net.load_state_dict(torch.load("beethoven_both_stacked_1.pkl"))
net.eval()
ltsm_gen_v2(net, 100, "beethoven_both_stacked_1", sampling_idx=0, time_step=0.2, n_steps=300, note_stuck=True)

# As can be heard, a time step smaller than 0.25 doesn't seem to be a good idea